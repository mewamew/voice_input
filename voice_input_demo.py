"""
è¯­éŸ³è¾“å…¥ Demo - ä½¿ç”¨éº¦å…‹é£å½•éŸ³å¹¶è°ƒç”¨é˜¿é‡Œäº‘ ASR æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
"""
import sounddevice as sd
import scipy.io.wavfile as wav
import numpy as np
import base64
import io
import os
from openai import OpenAI

# å½•éŸ³å‚æ•°
SAMPLE_RATE = 16000  # é‡‡æ ·ç‡
CHANNELS = 1  # å•å£°é“


def record_audio(duration: float = 5.0) -> np.ndarray:
    """
    å½•åˆ¶éŸ³é¢‘

    Args:
        duration: å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰

    Returns:
        å½•åˆ¶çš„éŸ³é¢‘æ•°æ®
    """
    print(f"ğŸ¤ å¼€å§‹å½•éŸ³ï¼Œè¯·è¯´è¯... ({duration}ç§’)")
    audio_data = sd.rec(
        int(duration * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=CHANNELS,
        dtype=np.int16
    )
    sd.wait()  # ç­‰å¾…å½•éŸ³å®Œæˆ
    print("âœ… å½•éŸ³å®Œæˆï¼")
    return audio_data


def audio_to_base64(audio_data: np.ndarray, sample_rate: int) -> str:
    """
    å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º base64 ç¼–ç çš„ WAV æ ¼å¼

    Args:
        audio_data: éŸ³é¢‘æ•°æ®
        sample_rate: é‡‡æ ·ç‡

    Returns:
        base64 ç¼–ç çš„éŸ³é¢‘å­—ç¬¦ä¸²
    """
    # å°†éŸ³é¢‘æ•°æ®å†™å…¥å†…å­˜ä¸­çš„ WAV æ–‡ä»¶
    buffer = io.BytesIO()
    wav.write(buffer, sample_rate, audio_data)
    buffer.seek(0)

    # è½¬æ¢ä¸º base64
    audio_base64 = base64.b64encode(buffer.read()).decode('utf-8')
    return audio_base64


def recognize_speech(audio_base64: str) -> str:
    """
    è°ƒç”¨é˜¿é‡Œäº‘ ASR æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«

    Args:
        audio_base64: base64 ç¼–ç çš„éŸ³é¢‘æ•°æ®

    Returns:
        è¯†åˆ«å‡ºçš„æ–‡å­—
    """
    # ä»ç¯å¢ƒå˜é‡è·å– API Key
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")

    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    # è°ƒç”¨ ASR æ¨¡å‹
    completion = client.chat.completions.create(
        model="qwen3-asr-flash",
        messages=[{
            "role": "user",
            "content": [{
                "type": "input_audio",
                "input_audio": {
                    "data": f"data:audio/wav;base64,{audio_base64}"
                }
            }]
        }],
        stream=False,
        extra_body={"asr_options": {"enable_itn": False}}
    )

    return completion.choices[0].message.content


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("è¯­éŸ³è¾“å…¥ Demo - é˜¿é‡Œäº‘ ASR")
    print("=" * 50)

    while True:
        # æç¤ºç”¨æˆ·è¾“å…¥å½•éŸ³æ—¶é•¿
        try:
            duration_input = input("\nè¯·è¾“å…¥å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤5ç§’ï¼Œè¾“å…¥ q é€€å‡ºï¼‰: ").strip()

            if duration_input.lower() == 'q':
                print("å†è§ï¼")
                break

            duration = float(duration_input) if duration_input else 5.0

            # å½•éŸ³
            audio_data = record_audio(duration)

            # è½¬æ¢ä¸º base64
            print("ğŸ”„ æ­£åœ¨å¤„ç†éŸ³é¢‘...")
            audio_base64 = audio_to_base64(audio_data, SAMPLE_RATE)

            # è¯­éŸ³è¯†åˆ«
            print("ğŸ”„ æ­£åœ¨è¯†åˆ«è¯­éŸ³...")
            text = recognize_speech(audio_base64)

            # è¾“å‡ºç»“æœ
            print("\n" + "=" * 50)
            print("ğŸ“ è¯†åˆ«ç»“æœ:")
            print(text)
            print("=" * 50)

        except KeyboardInterrupt:
            print("\n\nå·²ä¸­æ–­ï¼Œå†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main()
